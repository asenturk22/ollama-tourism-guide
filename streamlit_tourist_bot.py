"""
web uzerinde calisan chatbot ekrani gelistirme
streamlit framework
"""

import streamlit as st #streamlit ile web arayuzu olusturma kutuphanesi
from langchain_ollama import ChatOllama # ollama llm arayuzu
from langchain.schema import SystemMessage, HumanMessage # chat mesaj siniflari
from langchain.memory import ConversationBufferMemory # konusma gecmisi icin basit bir hafiza
import time

# Sayfa konfigurasyon ayarlari
st.set_page_config(
  page_title = "AkÄ±llÄ± Turist Rehberi", 
  page_icon="ğŸŒ",
  layout="wide"
)

# Baslik ve aciklamalar
st.title("ğŸŒ AkÄ±llÄ± Turist Rehberi")
st.markdown(
  """
  <div style="background-color: #f0f8ff; padding: 20px; border-radius: 10px; margin-bottom: 20px;'>
    <h3>ğŸ‡¹ğŸ‡· TÃ¼rkiye Turizm Rehberiniz</h3>
    <p>TÃ¼rkiye'nin dÃ¶rt bir yanÄ±ndaki turistik yerler, yÃ¶resel lezzetler, tarihi mekanlar ve seyahat Ã¶nerileri hakkÄ±nda detaylÄ± bilgi alabilirsiniz.</p>
    <p><strong>Ã–rnek sorular:</strong> Ä°stanbul'da gezilecek yerler nelerdir? Kapadokya'ya nasÄ±l gidilir? Gaziantep'in meÅŸhur yemekleri nelerdir?</p>
  </div>
  """, 
  unsafe_allow_html=True
)

# Sidebar ile model ayarlari
with st.sidebar:
  st.header("âš™ï¸ Ayarlar")

  # Model secimi
  model_options=["llama3.2:3b", "llama3.2:1b", "llama3.1:8b"]
  selected_model = st.selectbox("Model SeÃ§in: ", model_options, index=0)

  # Sicaklik ayari
  temperature = st.slider("Ãœretkenlik Seviyesi: ", 0.0, 1.0, 0.7, 0.1)

  # Gecmisi temizleme butonu
  if st.button("ğŸ—‘ï¸ Sohbet GeÃ§miÅŸini Temizle"):
    st.session_state.clear()
    st.rerun()

  st.markdown("---")
  st.markdown("ğŸ’¡ **Ä°pucu:** Daha spesifik sorular sorun!")

# session state baslatma (streamlit de kullanici gecmisini tutmak icin)
if "memory" not in st.session_state:
  st.session_state.memory = ConversationBufferMemory(return_messages=True) 

if "messages" not in st.session_state:
  st.session_state.messages = []

# LLM modelini baslat (hata yakalama ile)
# ollama ile llma 3.2 ile 3B parametreli modeli yukleyelim. 
@st.cache_resource
def initialize_llma(model_name, temp):
  try: 
    return ChatOllama(
      model=model_name, 
      temperature=temp
    )
  except Exception as e:
    st.error(f"Model yuklenirken hata oluÅŸtu : {str(e)}")
    st.error("LÃ¼tfen Ollama'nÄ±n Ã§alÄ±ÅŸtÄ±ÄŸÄ±ndan ve modelin yÃ¼klÃ¼ olduÄŸundan emin olun.")
    return None

llm = initialize_llma(selected_model, temperature)

# Sistem Mesaji
system_prompt = """Sen TÃ¼rkiye'nin en deneyimli ve bilgili turizm rehberisin. GÃ¶revin:

ğŸ¯ AMAÃ‡: TÃ¼rkiye'deki turizm deneyimlerini zenginleÅŸtirmek

ğŸ“ KAPSAM: 
- Åehirler ve bÃ¶lgeler hakkÄ±nda detaylÄ± bilgi
- Tarihi yerler ve kÃ¼ltÃ¼rel deÄŸerler
- YÃ¶resel yemekler ve mutfak kÃ¼ltÃ¼rÃ¼
- UlaÅŸÄ±m ve konaklama Ã¶nerileri
- Aktiviteler ve deneyimler
- Pratik seyahat ipuÃ§larÄ±

âœ¨ TARZIN:
- Samimi ve sÄ±cak
- DetaylÄ± ama anlaÅŸÄ±lÄ±r
- Pratik Ã¶neriler iÃ§eren
- KÃ¼ltÃ¼rel zenginlikleri vurgulayan

ğŸš€ HER CEVABINDA:
- Spesifik Ã¶neriler ver
- Fiyat aralÄ±klarÄ± belirt (mÃ¼mkÃ¼nse)
- Zaman tavsiyeleri ekle
- Alternatif seÃ§enekler sun
- Yerel ipuÃ§larÄ± paylaÅŸ
"""

# mesaj kutusu: kullanicidan gelen mesaj
user_input = st.chat_input("Bir ÅŸehir, mekan, yemek ya da aktivite sorabilirsiniz...")

if user_input: 
  # yeni gelen kullanici mesajini ilk olarak memory e ekliyor. 
  st.session_state.memory.chat_memory.add_user_message(user_input)

  # tum konusmayi modele verecek sekilde mesajlari olusturalim. sistem mesaji + memory + human message
  messages = [
    SystemMessage(content="Sen akÄ±llÄ± bir turizm ve turist rehberisin. "
      "KullanÄ±cÄ±lara TÃ¼rkiye'de ki ÅŸehirler, tarihi yerler, yÃ¶resel yemekler, ulaÅŸÄ±m ve tatil Ã¶nerileri hakkÄ±nda gÃ¼zel bilgler ver. "
    )
  ] + st.session_state.memory.load_memory_variables({})["history"] + [HumanMessage(content = user_input)]

  # modelden yanit al
  response = llm(messages)

  # yaniti hafizaya kaydet
  st.session_state.memory.chat_memory.add_ai_message(response.content)


# sohbet gecminisini arayuzde goster
# tum mesaj gecmisini sirasiyla gezip ekrana yazdiralim. 
for msg in st.session_state.memory.chat_memory.messages:
  if isinstance(msg, HumanMessage):
    with st.chat_message("Kullanici: "):
      st.markdown(msg.content)
  else: #ai ise
    with st.chat_message("Akilli Rehber: "):
      st.markdown(msg.content)
